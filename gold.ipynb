{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Applied AI in Biomedicine - Final Assignment**\n## PAC/PVC classification from ECG signals\n***\n* Alberto Rota: *Person Code: 10615751 - Student Number: 964662 - [alberto2.rota@mail.polimi.it](mailto:alberto2.rota@mail.polimi.it)*  \n* Gabriele Santicchi: *Person Code: 10579046 - Student Number: 969088 - [gabriele.santicchi@mail.polimi.it](mailto:gabriele.santicchi@mail.polimi.it)*\n***","metadata":{"_uuid":"43edb44f-a338-4d26-b422-3a21c5922ff3","_cell_guid":"91980425-82c1-4696-8301-848f66f6c54e","trusted":true}},{"cell_type":"code","source":"import os\nimport numpy as np, os, sys, joblib\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nmpl.rcParams.update(mpl.rcParamsDefault)\nimport seaborn as sns\nimport tarfile\nimport math\nimport random\nimport sklearn\nimport timeit\nimport json\nimport warnings\nimport random\n\nimport scipy\nfrom scipy.io import loadmat\nfrom random import randint\n\nimport tensorflow as tf\ntfk = tf.keras\ntfkl = tfk.layers\n\n\n#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn import preprocessing \nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\nSEED = 69\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\n\nprint(\"Using Tensorflow version\",tf.__version__)\nprint(\"RNG seed:\", SEED)\n\ncolor = {\n    \"lead\": \"#073b4c\",\n    \"N\": \"#06d6a0\",\n    \"S\": \"#ef476f\",\n    \"V\": \"#ffd166\",\n    \"X\": \"#118ab2\"\n}","metadata":{"_uuid":"a253ea42-ae15-4952-bab0-14a7ff1d4bcd","_cell_guid":"dcaeb367-8fdb-471d-ac7d-e4dbc71b8165","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T10:47:55.232670Z","iopub.execute_input":"2022-01-08T10:47:55.232944Z","iopub.status.idle":"2022-01-08T10:47:55.306479Z","shell.execute_reply.started":"2022-01-08T10:47:55.232914Z","shell.execute_reply":"2022-01-08T10:47:55.305603Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"dataset_dir = \"../input/ai-dataset/data\"","metadata":{"_uuid":"1e177c4a-4044-46f2-920f-fd4e8d7212e7","_cell_guid":"03728481-d59c-404b-9ea6-33c3e0636526","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:22.938695Z","iopub.execute_input":"2022-01-08T09:38:22.939006Z","iopub.status.idle":"2022-01-08T09:38:22.948796Z","shell.execute_reply.started":"2022-01-08T09:38:22.938971Z","shell.execute_reply":"2022-01-08T09:38:22.947203Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Patient class definition","metadata":{"_uuid":"fdeafa77-870c-4a3d-9bf4-17bea9776b01","_cell_guid":"218ce199-c730-4c7d-aae4-a8d3d4b17e3e","trusted":true}},{"cell_type":"code","source":"class Patient:\n    def __init__(self,init_dict):\n        self.path=init_dict['path']\n        self.fs=init_dict['fs']\n        self.id=init_dict['id']\n        self.rpeaks=init_dict['rpeaks']\n        self.peaklabels=init_dict['peaklabels']\n        self.samples=init_dict['samples']\n        self.time=np.arange(0,self.samples/self.fs,1/self.fs)\n        self.lead1=init_dict['lead1']\n        self.lead2=init_dict['lead2']\n        if self.fs != 128:\n            f1 = scipy.interpolate.interp1d(self.time,self.lead1)\n            f2 = scipy.interpolate.interp1d(self.time,self.lead2)\n            self.time=np.arange(0,self.samples/self.fs,1/self.fs)\n            self.fs = 128.0\n            self.lead1 = f1(self.time)\n            self.lead2 = f2(self.time)\n        \n        insideborders = np.logical_and(self.rpeaks>0, self.rpeaks<self.samples)\n        \n        if self.rpeaks.shape[0]-np.count_nonzero(insideborders)>0: \n            print(f\"PATIENT {self.id}: Found {self.rpeaks.shape[0]-np.count_nonzero(insideborders)} samples out of bounds\")\n            self.rpeaks = self.rpeaks[insideborders]\n            self.peaklabels = self.peaklabels[insideborders]\n                                \n    def info(self):\n        print(\">> ID:\",self.id)\n        print(\" | Path:\",self.path)\n        print(\" | fs:\",self.fs)\n        print(\" | samples:\",self.samples)\n        print(\" | lead1:\",self.lead1)\n        print(\" | lead2:\",self.lead2)\n        print(\" | rpeaks:\",self.rpeaks)\n        print(\" | peaklabels:\",self.peaklabels)\n        \n    def plot(self,windowstart=None,xrange=4000,splitleads=False):\n        if windowstart is None: windowstart = randint(0,self.samples-xrange)\n        \n        if not splitleads: \n            plt.figure(figsize=(10,7))\n            plt.subplot(2,1,1)\n        if splitleads: plt.figure(figsize=(10,2.5))\n        plt.plot(self.time,self.lead1,color=color['lead'])\n        plt.scatter(self.rpeaks[self.peaklabels=='N']/self.fs,self.lead1[self.rpeaks[self.peaklabels=='N']],\n            color=color['N'],s=500,alpha=0.5,label=\"Normal\")\n        plt.scatter(self.rpeaks[self.peaklabels=='S']/self.fs,self.lead1[self.rpeaks[self.peaklabels=='S']],\n            color=color['S'],s=500,alpha=0.5,label=\"SopraVentricular\")\n        plt.scatter(self.rpeaks[self.peaklabels=='V']/self.fs,self.lead1[self.rpeaks[self.peaklabels=='V']],\n            color=color['V'],s=500,alpha=0.5,label=\"Ventricular\")\n        plt.grid(True)\n        plt.xlim([windowstart/self.fs,(windowstart+xrange)/self.fs])\n        plt.title(f\"Patient #{self.id} - ECG lead 1\")\n        if splitleads: plt.xlabel(\"Time [seconds]\")\n        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n        if splitleads: plt.show()\n        \n        if not splitleads: \n            plt.subplot(2,1,2)\n        if splitleads: plt.figure(figsize=(10,2.5))\n        plt.plot(self.time,self.lead2,color=color['lead'])\n        plt.scatter(self.rpeaks[self.peaklabels=='N']/self.fs,self.lead2[self.rpeaks[self.peaklabels=='N']],\n            color=color['N'],s=500,alpha=0.5,label=\"Normal\")\n        plt.scatter(self.rpeaks[self.peaklabels=='S']/self.fs,self.lead2[self.rpeaks[self.peaklabels=='S']],\n            color=color['S'],s=500,alpha=0.5,label=\"SopraVentricular\")\n        plt.scatter(self.rpeaks[self.peaklabels=='V']/self.fs,self.lead2[self.rpeaks[self.peaklabels=='V']],\n            color=color['V'],s=500,alpha=0.5,label=\"Ventricular\")\n        plt.grid(True)\n        plt.xlim([windowstart/self.fs,(windowstart+xrange)/self.fs])\n        plt.title(f\"Patient #{self.id} - ECG lead 2\")\n        plt.xlabel(\"Time [seconds]\")\n        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n        plt.show()\n\n    def split_RRR(self,borders=0.05, fixed_length=False):\n        border_samples = round(borders*(self.rpeaks[0]))\n        \n        wl1 = [self.lead1[0:(self.rpeaks[0]-border_samples)]]\n        wl2 = [self.lead1[0:(self.rpeaks[0]-border_samples)]]\n        \n        for p in range(1,self.rpeaks.shape[0]-1):\n            border_samples = round(borders*(self.rpeaks[p+1]-self.rpeaks[p-1]))\n            window = self.lead1[(self.rpeaks[p-1]+border_samples):(self.rpeaks[p+1]-border_samples)]\n            wl1.append(window)\n            window = self.lead2[(self.rpeaks[p-1]+border_samples):(self.rpeaks[p+1]-border_samples)]\n            wl2.append(window)\n        \n        border_samples = round(borders*(self.rpeaks[0]))\n        wl1.append(self.lead1[self.rpeaks[-1]:self.samples])\n        wl2.append(self.lead1[self.rpeaks[-1]:self.samples])\n        \n        if fixed_length != False:\n            r1,r2 = [],[]\n            for i,_ in enumerate(wl1):\n                if wl1[i].shape[0] >= fixed_length:\n                    r1.append(\n                        wl1[i][wl1[i].shape[0]//2-fixed_length//2:wl1[i].shape[0]//2+(fixed_length-fixed_length//2)]\n                    )\n                    r2.append(\n                        wl2[i][wl2[i].shape[0]//2-fixed_length//2:wl2[i].shape[0]//2+(fixed_length-fixed_length//2)]\n                    )\n                elif wl1[i].shape[0] < fixed_length:\n                    padleft  = (fixed_length-wl1[i].shape[0])//2\n                    padright = fixed_length-padleft-wl1[i].shape[0]\n                    r1.append(\n                        np.pad(wl1[i], (padleft,padright), mode='edge')\n                    )\n                    r2.append(\n                        np.pad(wl2[i], (padleft,padright), mode='edge')\n                    )\n                elif wl1[i].shape[0] == fixed_length:\n                    r1.append(\n                        wl1[i][-fixed_length:]\n                    )\n                    r2.append(\n                        wl2[i][-fixed_length:]\n                    )\n            wl1,wl2 = r1,r2\n        return wl1,wl2\n        \n    def split_windows(self, width=100):\n        wl1,wl2=[],[]\n        \n        right = width//2\n        left = width-right\n        LEN = self.lead1.shape[0]\n\n        for i in range(self.rpeaks.shape[0]):\n            peak = self.rpeaks[i]\n            \n            if peak-left >= 0 and peak+right < LEN: \n                window = self.lead1[(peak-left):(peak+right)]\n            elif peak-left < 0:\n                window = np.pad(self.lead1[0:(peak+right)],(abs(width-(peak+right)),0))\n                \n            elif peak+right >= LEN:\n                window = np.pad(self.lead1[(peak-left):LEN],(0,abs(width-(LEN-(peak-left)))))\n                \n            wl1.append(window)\n            \n            if peak-left >= 0 and peak+right < LEN: \n                window = self.lead2[(peak-left):(peak+right)]\n            elif peak-left < 0:\n                window = np.pad(self.lead2[0:(peak+right)],(abs(width-(peak+right)),0))\n                \n            elif peak+right >= LEN:\n                window = np.pad(self.lead2[(peak-left):LEN],(0,abs(width-(LEN-(peak-left)))))\n            \n            wl2.append(window)\n\n        return wl1,wl2","metadata":{"_uuid":"0b2ff125-581e-4535-a0a2-5643c6fe32ab","_cell_guid":"d80845dc-8925-41b0-b126-fbe8e9b9f5a6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:23.624645Z","iopub.execute_input":"2022-01-08T09:38:23.625209Z","iopub.status.idle":"2022-01-08T09:38:23.667632Z","shell.execute_reply.started":"2022-01-08T09:38:23.625170Z","shell.execute_reply":"2022-01-08T09:38:23.666821Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{"_uuid":"bac097e1-2ff9-49d8-81be-5210e52a7959","_cell_guid":"87b4cf7a-731c-44aa-a03b-f11e285eff5e","trusted":true}},{"cell_type":"code","source":"files = sorted(os.listdir(dataset_dir))\npatient = []\ncorrect,ncorrect=0,0\nfor f in range(0,len(files),3):\n    try: \n        recs = loadmat(os.path.join(dataset_dir,files[f]))\n        ann = loadmat(os.path.join(dataset_dir,files[f+1]))\n        rp =loadmat(os.path.join(dataset_dir,files[f+2]))\n        patient_as_dict={\n                'id':files[f].split(\".\")[0].split(\"_\")[0],\n                'path':os.path.join(\"data\",files[f]),\n                'fs':float(files[f].split(\".\")[0].split(\"_\")[1]),\n                'samples':recs['ecg'][:,0].shape[0],\n                'lead1':recs['ecg'][:,0],\n                'lead2':recs['ecg'][:,1],\n                'rpeaks':rp['rpeaks'].T[0],\n                'peaklabels':ann['labels'] \n        }\n        patient.append(Patient(patient_as_dict))\n        correct+=1\n        \n    except:\n        ncorrect+=1\n        \nprint(f\"Loaded {correct} files correctly\")\nif ncorrect>0: print(f\"!!!! Error in loading {ncorrect} files\")\nptest = patient[9] # Test patient","metadata":{"_uuid":"34cdefee-5a9c-47b8-ae2a-418549b29cbf","_cell_guid":"e2efec51-e648-45f2-8876-267ade4f4efa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:25.890194Z","iopub.execute_input":"2022-01-08T09:38:25.890491Z","iopub.status.idle":"2022-01-08T09:38:33.101834Z","shell.execute_reply.started":"2022-01-08T09:38:25.890445Z","shell.execute_reply":"2022-01-08T09:38:33.101089Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Examples of ECG signals","metadata":{"_uuid":"ac2a4b78-95a1-40e1-b825-42a3b06c5d63","_cell_guid":"dd49e433-265f-43be-884b-f38a0ce1e3ae","trusted":true}},{"cell_type":"code","source":"patient[38].plot(180*patient[38].fs,30*patient[38].fs) # 1 Sopraventricular, 1 Ventricular\n# patient[13].plot() # Lots of Sopraventriculars\n# patient[9].plot() # Lots of both Sopraventriculars and Ventriculars\n# patient[0].plot(60000,5000) # Baseline wonder","metadata":{"_uuid":"a4b27de0-5b2e-4e94-be3d-9b53e2d1eac1","_cell_guid":"88843ff2-e14b-478a-854f-adf6db54932e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:33.103274Z","iopub.execute_input":"2022-01-08T09:38:33.103691Z","iopub.status.idle":"2022-01-08T09:38:33.624019Z","shell.execute_reply.started":"2022-01-08T09:38:33.103650Z","shell.execute_reply":"2022-01-08T09:38:33.623357Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Window splitting","metadata":{"_uuid":"23a61913-f3ed-46fa-b8eb-503476c7dd5e","_cell_guid":"03af5dcf-529a-43fb-bdcc-7462ae6c27c1","trusted":true}},{"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.subplot(1,2,1)\n\nints = []\nwins = []\nN_count = 0\nS_count = 0\nV_count = 0\n\nfor ptest in patient:\n    nn = np.where(np.logical_or(ptest.peaklabels=='V',ptest.peaklabels=='S'))\n    intervals = np.diff(nn)[0]\n    wins.append(np.diff(ptest.rpeaks))\n    ints.append(intervals)\n    N_count+=np.count_nonzero(ptest.peaklabels=='N')\n    S_count+=np.count_nonzero(ptest.peaklabels=='S')\n    V_count+=np.count_nonzero(ptest.peaklabels=='V')\n    \nintervals = np.concatenate(ints,axis=0)\nRRR = np.concatenate(wins,axis=0)\nrng=[0,20]\nplt.hist(intervals,bins=rng[-1],range=rng,color=color['X'])\n# plt.xticks(range(rng[-1]))\nplt.xlabel(\"Pathological Heartbeat distance\")\n# plt.grid(True)\n\nplt.subplot(1,2,2)\nplt.hist(RRR,color=color['X'], range=[0,500],bins=20)\nplt.xlabel(\"RRR distance (in samples)\")\n# plt.xticks(range(rng[-1]))\n# plt.title(\"Density of distance (in heartbeats) between adjacent pathological heartbeats\")\n# plt.grid(True)\nplt.show()","metadata":{"_uuid":"87a70571-8d27-4603-9691-aa985fb8be83","_cell_guid":"41b45537-257b-45c9-b3f3-a2dabb56cd1f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:39.279165Z","iopub.execute_input":"2022-01-08T09:38:39.279866Z","iopub.status.idle":"2022-01-08T09:38:39.645266Z","shell.execute_reply.started":"2022-01-08T09:38:39.279824Z","shell.execute_reply":"2022-01-08T09:38:39.644581Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Difference in splitting strategies:\n* **`Split_RRR(fixed_length==False)`** keeps only the desired R-peak in the window --> INCONSISTENCY in window length","metadata":{"_uuid":"34044500-2240-4c4a-9ffa-f9a3feddca6e","_cell_guid":"443d6aaf-6b08-4219-b164-26247b01e2dd","trusted":true}},{"cell_type":"code","source":"split1,_ = ptest.split_RRR(borders=0.05)\nidxs = [randint(0,1000) for _ in range(4)]\nplt.figure(figsize=(12,1))\nfor p,i in enumerate(idxs):\n    plt.subplot(1,4,p+1)\n    plt.plot(split1[i],color=color['S'])\n    plt.title(f\"W{i}: length={len(split1[i])}\")        \n    yt,_ = plt.yticks()\n    plt.yticks(ticks=yt,labels=[])\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.grid(True)\nplt.show()","metadata":{"_uuid":"1abc2b2e-13da-413a-9b58-26bd836ee24c","_cell_guid":"42f03019-9410-4ffa-b2cc-6aa7529f041f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:41.661294Z","iopub.execute_input":"2022-01-08T09:38:41.661868Z","iopub.status.idle":"2022-01-08T09:38:42.079385Z","shell.execute_reply.started":"2022-01-08T09:38:41.661827Z","shell.execute_reply":"2022-01-08T09:38:42.078681Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"* **`Split_RRR(fixed_length==True)`** keeps only the desired R-peak in the window and pads/cuts to fix the window width --> CONSISTENCY in window length","metadata":{"_uuid":"e6b40848-9cdc-42bc-a34c-970c6a977535","_cell_guid":"acd21652-ceed-4cd1-9fcf-3fdcd52150e6","trusted":true}},{"cell_type":"code","source":"\nsplit1,_ = ptest.split_RRR(borders=0.05,fixed_length=150)\nidxs = [randint(0,1000) for _ in range(4)]\nplt.figure(figsize=(12,1))\nfor p,i in enumerate(idxs):\n    plt.subplot(1,4,p+1)\n    plt.plot(split1[i],color=color['N'])\n    plt.title(f\"W{i}: length={len(split1[i])}\")        \n    yt,_ = plt.yticks()\n    plt.yticks(ticks=yt,labels=[])\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.grid(True)\nplt.show()","metadata":{"_uuid":"fde4f805-a1cf-45ea-affd-302ae26291cd","_cell_guid":"4be4365b-d4e7-41de-95c4-440baeff161f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:42.386217Z","iopub.execute_input":"2022-01-08T09:38:42.386766Z","iopub.status.idle":"2022-01-08T09:38:42.798401Z","shell.execute_reply.started":"2022-01-08T09:38:42.386725Z","shell.execute_reply":"2022-01-08T09:38:42.797612Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"* **`split_windows(width=150)`** slices a fixed number of samples around each R-peak --> Multiple peaks may appear in the same window","metadata":{"_uuid":"84d4c955-892a-480b-9b86-3b907c2ffc80","_cell_guid":"ac35b4f8-8ef5-4e04-9640-b98d2667eb5a","trusted":true}},{"cell_type":"code","source":"split1,_ = ptest.split_windows(150)\nidxs = [randint(0,1000) for _ in range(4)]\nplt.figure(figsize=(12,1))\nfor p,i in enumerate(idxs):\n    plt.subplot(1,4,p+1)\n    plt.plot(split1[i],color=color['X'])\n    plt.title(f\"W{i}: length={len(split1[i])}\")        \n    yt,_ = plt.yticks()\n    plt.yticks(ticks=yt,labels=[])\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.grid(True)\nplt.show()","metadata":{"_uuid":"6c25614b-6928-4c4b-a123-7c61f00e463a","_cell_guid":"666a6efd-9d2c-4070-a5c3-40d04a715220","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:46.040900Z","iopub.execute_input":"2022-01-08T09:38:46.041475Z","iopub.status.idle":"2022-01-08T09:38:46.667476Z","shell.execute_reply.started":"2022-01-08T09:38:46.041437Z","shell.execute_reply":"2022-01-08T09:38:46.666758Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Label encoding\n* **N**: Normal\n* **S**: Sopraventricular\n* **V**: Ventricular\n* **X**: A virtual label used to classify the first beats in the recording, on which there is no information about the past","metadata":{"_uuid":"f8d6f1a6-2f25-4130-946e-a50202197caf","_cell_guid":"ed48c4b1-65eb-49ab-86e2-2ec41b9afb8f","trusted":true}},{"cell_type":"code","source":"categorical = {'X':np.array([1,0,0,0]),'N':np.array([0,1,0,0]),'S':np.array([0,0,1,0]),'V':np.array([0,0,0,1])}","metadata":{"_uuid":"4a6ae49c-65b1-4b3b-a59b-ca8b2f1c0d73","_cell_guid":"b6d37059-0e0c-40fd-836d-54b2d9ca0c16","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T09:38:47.336808Z","iopub.execute_input":"2022-01-08T09:38:47.337089Z","iopub.status.idle":"2022-01-08T09:38:47.343023Z","shell.execute_reply.started":"2022-01-08T09:38:47.337058Z","shell.execute_reply":"2022-01-08T09:38:47.342288Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Building the Dataset\nAnd performing patient-wise undersampling on N windows","metadata":{"_uuid":"b6e4bed3-ec3f-44b1-80eb-ac41437ae98d","_cell_guid":"118d546b-229d-41a2-8f28-418f616fa815","trusted":true}},{"cell_type":"code","source":"N_to_take = round(min([V_count,N_count,S_count])/len(patient))\n\ndef build_dataset(patients, width=150):\n    XtrainWins=[]\n    XtrainPast=[]\n    Ytrain=[]\n    for p in patients:\n        split1,split2 = p.split_RRR(borders=0.05, fixed_length=width)\n        vect = np.arange(0,len(split1))\n        np.random.shuffle(vect)\n        N = 0\n        for i in vect:\n            if (p.peaklabels[i] != 'N' ):\n                XtrainWins.append(\n                    np.column_stack((split1[i],split2[i]))\n                )\n                Ytrain.append(\n                    categorical[p.peaklabels[i]]\n                )\n                if i>=2:\n                    XtrainPast.append(\n                        np.array([categorical[p.peaklabels[i-2]],categorical[p.peaklabels[i-1]]])\n                    )\n                elif i==1:\n                    XtrainPast.append(\n                        np.array([categorical['X'],categorical[p.peaklabels[i-1]]])\n                    )\n                else:\n                    XtrainPast.append(\n                        np.array([categorical['X'],categorical['X']])\n                    )\n            if (p.peaklabels[i] == 'N' and N < N_to_take):\n                XtrainWins.append(\n                np.column_stack((split1[i],split2[i]))\n                )\n                Ytrain.append(\n                    categorical[p.peaklabels[i]]\n                )\n                if i>=2:\n                    XtrainPast.append(\n                        np.array([categorical[p.peaklabels[i-2]],categorical[p.peaklabels[i-1]]])\n                    )\n                elif i==1:\n                    XtrainPast.append(\n                        np.array([categorical['X'],categorical[p.peaklabels[i-1]]])\n                    )\n                else:\n                    XtrainPast.append(\n                        np.array([categorical['X'],categorical['X']])\n                    )\n                N = N + 1\n            \n    return (np.stack(XtrainWins,axis=0),np.stack(XtrainPast,axis=0)),np.stack(Ytrain,axis=0)\n\n(XtrainW,XtrainP),Ytrain=build_dataset(patient,150)\n\nprint(f\"INPUT WINDOW shape: {XtrainW.shape} as (WINDOW, TIME, LEAD)\")\nprint(f\"INPUT PAST shape: {XtrainP.shape} as (WINDOW, PAST, one-hot-LABEL)\")\nprint(f\"OUTPUT shape: {Ytrain.shape} as (WINDOW, one-hot-LABEL)\")","metadata":{"_uuid":"e309b946-2d58-4b37-8a9c-c1ce2a3ec662","_cell_guid":"96d21ed3-304b-47af-a5a5-23c3a2d26875","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T10:37:54.424857Z","iopub.execute_input":"2022-01-08T10:37:54.425202Z","iopub.status.idle":"2022-01-08T10:38:04.454029Z","shell.execute_reply.started":"2022-01-08T10:37:54.425161Z","shell.execute_reply":"2022-01-08T10:38:04.453228Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test-Validation Split","metadata":{"_uuid":"21f0d468-920c-4116-9c49-c43d284aa409","_cell_guid":"ca14e641-c235-49ea-b5a4-aac35945064c","trusted":true}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nXtrainW,XvalW,XtrainP,XvalP,Ytrain,Yval = train_test_split(\n    XtrainW,XtrainP,Ytrain, test_size=0.3, shuffle=True, stratify=Ytrain)\n\nXvalW,XtestW,XvalP,XtestP,Yval,Ytest = train_test_split(\n    XvalW,XvalP,Yval, test_size=0.3, shuffle=True, stratify=Yval)\n\nprint(f\"{len(XtrainW)} TRAINING samples: {XtrainW[0].shape}[Window] + {XtrainP[0].shape}[Past Labels] --> {Ytrain[0].shape}[Classification]\")\nprint(f\"{len(XvalW)} VALIDATION samples: {XvalW[0].shape}[Window] + {XvalP[0].shape}[Past Labels] --> {Yval[0].shape}[Classification]\")\nprint(f\"{len(XtestW)} TESTING samples: {XtestW[0].shape}[Window] + {XtestP[0].shape}[Past Labels] --> {Ytest[0].shape}[Classification]\")","metadata":{"_uuid":"957dc816-9d3c-4310-85ae-ad660e69fe68","_cell_guid":"cea5270b-8d05-44c3-9c79-7481a8358183","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T10:38:04.458756Z","iopub.execute_input":"2022-01-08T10:38:04.461176Z","iopub.status.idle":"2022-01-08T10:38:04.992145Z","shell.execute_reply.started":"2022-01-08T10:38:04.461128Z","shell.execute_reply":"2022-01-08T10:38:04.991432Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"# Building the Time Model","metadata":{"_uuid":"a18ae36a-7e5b-4738-985a-d288f3358c2e","_cell_guid":"5f6eafd5-ef02-4d66-a430-785c073b144d","trusted":true}},{"cell_type":"code","source":"def build_time_model(inputwin_shape,inputpast_shape, classes):\n    \n    inputwin_layer = tfkl.Input(shape=inputwin_shape, name='InputWin')\n    inputpast_layer = tfkl.Input(shape=inputpast_shape, name='InputPast')\n\n    x = tfkl.LSTM(128, return_sequences=True)(inputwin_layer)\n    x = tfkl.Conv1D(filters = 8, kernel_size=5)(x)\n    x = tfkl.LSTM(128,return_sequences=True)(x)\n    x = tfkl.Dropout(.5, seed=SEED)(x)\n    x = tfkl.Dense(32, activation='relu')(x)\n    x = tfkl.Flatten()(x)\n    x = tfkl.Dense(classes, activation='softmax')(x)\n    \n    x2 = tfkl.Reshape((1,4))(x)\n    xc = tfkl.Concatenate(axis=1)([inputpast_layer,x2])\n    x = tfkl.Flatten()(xc)\n    output_layer = tfkl.Dense(classes,activation='softmax')(x)\n    \n    model = tfk.Model(inputs=[inputwin_layer,inputpast_layer], outputs=output_layer, name='PAC_PVC_classifier')\n\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n\n    return model \n\ntimemodel = build_time_model(inputwin_shape=XtrainW[0].shape,inputpast_shape=XtrainP[0].shape, classes=4)\ntimemodel.summary()\ntfk.utils.plot_model(timemodel,show_shapes=True)","metadata":{"_uuid":"ae346b7a-b3af-4057-86c2-446e354f6a31","_cell_guid":"cc461ba8-119e-47d0-9339-69450ff6805d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T10:16:23.313323Z","iopub.execute_input":"2022-01-08T10:16:23.313595Z","iopub.status.idle":"2022-01-08T10:16:24.072261Z","shell.execute_reply.started":"2022-01-08T10:16:23.313558Z","shell.execute_reply":"2022-01-08T10:16:24.071464Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Building the Frequency Model","metadata":{}},{"cell_type":"code","source":"def build_freq_model(inputwin_shape,inputpast_shape, classes):\n    \n    inputwin_layer = tfkl.Input(shape=inputwin_shape, name='InputWin')\n    inputpast_layer = tfkl.Input(shape=inputpast_shape, name='InputPast')\n\n    x = tfkl.Conv1D(filters = 8, kernel_size=3)(inputwin_layer)\n    x = tfkl.Activation('relu')(x)\n    x = tfkl.MaxPooling1D(2)(x)\n    x = tfkl.Conv1D(filters = 16, kernel_size=3)(x)\n    x = tfkl.Activation('relu')(x)\n    x = tfkl.MaxPooling1D(2)(x)\n    x = tfkl.Conv1D(filters = 32, kernel_size=3)(x)\n    x = tfkl.Activation('relu')(x)\n    x = tfkl.MaxPooling1D(2)(x)\n    x = tfkl.Dropout(.5, seed=SEED)(x)\n    x = tfkl.Flatten()(x)\n    x = tfkl.Dense(32, activation='relu')(x)\n    x = tfkl.Dense(classes, activation='softmax')(x)\n    \n    x2 = tfkl.Reshape((1,4))(x)\n    xc = tfkl.Concatenate(axis=1)([inputpast_layer,x2])\n    x = tfkl.Flatten()(xc)\n    output_layer = tfkl.Dense(classes,activation='softmax')(x)\n    \n    model = tfk.Model(inputs=[inputwin_layer,inputpast_layer], outputs=output_layer, name='PAC_PVC_classifier')\n\n    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n\n    return model \n\nfreqmodel = build_freq_model(inputwin_shape=XtrainW[0].shape,inputpast_shape=XtrainP[0].shape, classes=4)\nfreqmodel.summary()\ntfk.utils.plot_model(freqmodel,show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T10:16:24.074982Z","iopub.execute_input":"2022-01-08T10:16:24.075496Z","iopub.status.idle":"2022-01-08T10:16:24.537810Z","shell.execute_reply.started":"2022-01-08T10:16:24.075452Z","shell.execute_reply":"2022-01-08T10:16:24.536097Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(\"CLASS WEIGHTING\")\nN_count=np.count_nonzero(np.argmax(Ytrain,axis=1)==1)\nS_count=np.count_nonzero(np.argmax(Ytrain,axis=1)==2)\nV_count=np.count_nonzero(np.argmax(Ytrain,axis=1)==3)\n\nN_samples = N_count+V_count+S_count\nCLASS_WEIGHT = {\n    0:0,\n    1:N_samples/(3*N_count),\n    2:N_samples/(3*S_count),\n    3:N_samples/(3*V_count),\n}\nprint(CLASS_WEIGHT)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T10:58:07.258223Z","iopub.execute_input":"2022-01-08T10:58:07.258560Z","iopub.status.idle":"2022-01-08T10:58:07.266886Z","shell.execute_reply.started":"2022-01-08T10:58:07.258521Z","shell.execute_reply":"2022-01-08T10:58:07.266052Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"# Training the Time Classifier","metadata":{"_uuid":"b7235d92-3772-49ec-8de0-9a42de3a5b10","_cell_guid":"b380ddbf-e19e-42b4-bd92-b6f97238e151","trusted":true}},{"cell_type":"code","source":"BATCH_SIZE=256\nEPOCHS=200\nLEARNING_RATE=1e-3\n\n(XtrainW,XtrainP),Ytrain=build_dataset(patient,150)\nprint()\nprint(f\"INPUT WINDOW shape: {XtrainW.shape} as (WINDOW, TIME, LEAD)\")\nprint(f\"INPUT PAST shape: {XtrainP.shape} as (WINDOW, PAST, one-hot-LABEL)\")\nprint(f\"OUTPUT shape: {Ytrain.shape} as (WINDOW, one-hot-LABEL)\")\n\nXtrainW,XvalW,XtrainP,XvalP,Ytrain,Yval = train_test_split(\n    XtrainW,XtrainP,Ytrain, test_size=0.3, shuffle=True, stratify=Ytrain)\n\nXvalW,XtestW,XvalP,XtestP,Yval,Ytest = train_test_split(\n    XvalW,XvalP,Yval, test_size=0.3, shuffle=True, stratify=Yval)\nprint()\nprint(f\"{len(XtrainW)} TRAINING samples: {XtrainW[0].shape}[Window] + {XtrainP[0].shape}[Past Labels] --> {Ytrain[0].shape}[Classification]\")\nprint(f\"{len(XvalW)} VALIDATION samples: {XvalW[0].shape}[Window] + {XvalP[0].shape}[Past Labels] --> {Yval[0].shape}[Classification]\")\nprint(f\"{len(XtestW)} TESTING samples: {XtestW[0].shape}[Window] + {XtestP[0].shape}[Past Labels] --> {Ytest[0].shape}[Classification]\")\nprint()\ntimemodel = build_time_model(inputwin_shape=XtrainW[0].shape,inputpast_shape=XtrainP[0].shape, classes=4)\n\ntimemodel.compile(\n    loss = tfk.losses.CategoricalCrossentropy(),\n    optimizer=tfk.optimizers.Adam(learning_rate=LEARNING_RATE),\n    metrics = [\n        'accuracy',\n        tfk.metrics.Recall(class_id=1,name='recall_N'),\n        tfk.metrics.Recall(class_id=2,name='recall_S'),\n        tfk.metrics.Recall(class_id=3,name='recall_V'),\n    ]\n)\n\nhistory = timemodel.fit(\n    x = [XtrainW,XtrainP],\n    y = Ytrain,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    class_weight=CLASS_WEIGHT,  \n    validation_data=([XvalW,XvalP],Yval),\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='recall_S', mode='max', patience=50),        \n        tfk.callbacks.EarlyStopping(monitor='recall_V', mode='max', patience=50),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=25, verbose=1)\n    ],\n).history\n\nprint(\">> TRAINING HISTORY\")\nplt.figure(figsize=(15,10))\nplt.subplot(2,1,1)\nplt.plot(history['loss'], label='Training Loss', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_loss'], label='Validation Loss', alpha=.9, color='#5a9aa5')\nplt.title('Loss')\nplt.legend()\nplt.grid(alpha=.3)\nplt.subplot(2,1,2)\nplt.plot(history['accuracy'], label='Training Accuracy', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_accuracy'], label='Validation Accuracy', alpha=.9, color='#5a9aa5')\nplt.title('Accuracy')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\npreds=np.argmax(timemodel.predict([XtestW, XtestP]),axis=1)\nYtestt = np.argmax(Ytest,axis=1)\ncorrects = preds==Ytestt\nprint(\"ACCURAY: \",np.count_nonzero(corrects)/corrects.shape[0])\n\nprint(\"CONFUSION MATRIX\")\nprint(sklearn.metrics.confusion_matrix(Ytestt,preds))\nprint()\nprint()\nprint(sklearn.metrics.classification_report(Ytestt,preds))\n\ncm = sklearn.metrics.confusion_matrix(Ytestt,preds)/np.sum(sklearn.metrics.confusion_matrix(Ytestt,preds),axis=0)\nhm=sns.heatmap(cm,annot=True,fmt=\".2f\")\nhm.set_xticklabels(['N','S','V'])\nhm.set_xlabel(\"Prediction\")\nhm.set_ylabel(\"Real\")\nhm.set_yticklabels(['N','S','V'])\nplt.show()","metadata":{"_uuid":"30513367-3516-42ac-b44b-52c4c7836f17","_cell_guid":"f669c3f4-9973-4e77-8313-a805474b416a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-08T10:48:28.590280Z","iopub.execute_input":"2022-01-08T10:48:28.591039Z","iopub.status.idle":"2022-01-08T10:58:07.256637Z","shell.execute_reply.started":"2022-01-08T10:48:28.590999Z","shell.execute_reply":"2022-01-08T10:58:07.255037Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"# Training the Frequency classifier","metadata":{}},{"cell_type":"code","source":"(XtrainW,fXtrainP),fYtrain=build_dataset(patient,150)\nfXtrainW = np.abs(np.fft.fft(XtrainW,axis=1))\n\nprint()\nprint(f\"INPUT WINDOW shape: {fXtrainW.shape} as (WINDOW, TIME, LEAD)\")\nprint(f\"INPUT PAST shape: {fXtrainP.shape} as (WINDOW, PAST, one-hot-LABEL)\")\nprint(f\"OUTPUT shape: {fYtrain.shape} as (WINDOW, one-hot-LABEL)\")\n\nfXtrainW,fXvalW,fXtrainP,fXvalP,fYtrain,fYval = train_test_split(\n    fXtrainW,fXtrainP,fYtrain, test_size=0.3, shuffle=True, stratify=fYtrain)\n\nfXvalW,fXtestW,fXvalP,fXtestP,fYval,fYtest = train_test_split(\n    fXvalW,fXvalP,fYval, test_size=0.3, shuffle=True, stratify=fYval)\nprint()\nprint(f\"{len(fXtrainW)} TRAINING samples: {fXtrainW[0].shape}[Window] + {fXtrainP[0].shape}[Past Labels] --> {fYtrain[0].shape}[Classification]\")\nprint(f\"{len(fXvalW)} VALIDATION samples: {fXvalW[0].shape}[Window] + {fXvalP[0].shape}[Past Labels] --> {fYval[0].shape}[Classification]\")\nprint(f\"{len(fXtestW)} TESTING samples: {fXtestW[0].shape}[Window] + {fXtestP[0].shape}[Past Labels] --> {fYtest[0].shape}[Classification]\")\nprint()\nBATCH_SIZE=256\nEPOCHS=300\nLEARNING_RATE=1e-3\n\nfreqmodel = build_freq_model(inputwin_shape=fXtrainW[0].shape,inputpast_shape=fXtrainP[0].shape, classes=4)\n\nfreqmodel.compile(\n    loss = tfk.losses.CategoricalCrossentropy(),\n    optimizer=tfk.optimizers.Adam(learning_rate=LEARNING_RATE),\n    metrics = [\n        'accuracy',\n        tfk.metrics.Recall(class_id=1,name='recall_N'),\n        tfk.metrics.Recall(class_id=2,name='recall_S'),\n        tfk.metrics.Recall(class_id=3,name='recall_V'),\n    ]\n)\n\nhistory = freqmodel.fit(\n    x = [fXtrainW,fXtrainP],\n    y = fYtrain,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    class_weight=CLASS_WEIGHT,  \n    validation_data=([fXvalW,fXvalP],fYval),\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='recall_S', mode='max', patience=50),        \n        tfk.callbacks.EarlyStopping(monitor='recall_V', mode='max', patience=50),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=25, verbose=1)\n    ],\n).history\n\nprint(\">> TRAINING HISTORY\")\nplt.figure(figsize=(15,10))\nplt.subplot(3,1,1)\nplt.plot(history['loss'], label='Training Loss', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_loss'], label='Validation Loss', alpha=.9, color='#5a9aa5')\nplt.title('Loss')\nplt.legend()\nplt.grid(alpha=.3)\nplt.subplot(3,1,2)\nplt.plot(history['recall_S'], label='Training Recall S', alpha=.8, color='#ff0000')\nplt.plot(history['val_recall_S'], label='Validation Recall S', alpha=.9, color='#ff0000')\nplt.plot(history['recall_V'], label='Training Recall V', alpha=.8, color='#0000ff')\nplt.plot(history['val_recall_V'], label='Validation Recall V', alpha=.9, color='#0000ff')\nplt.title('Loss')\nplt.legend()\nplt.grid(alpha=.3)\nplt.subplot(3,1,3)\nplt.plot(history['accuracy'], label='Training Accuracy', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_accuracy'], label='Validation Accuracy', alpha=.9, color='#5a9aa5')\nplt.title('Accuracy')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\npreds=np.argmax(freqmodel.predict([fXtestW, fXtestP]),axis=1)\nYtestt = np.argmax(fYtest,axis=1)\ncorrects = preds==Ytestt\nprint(\"ACCURAY: \",np.count_nonzero(corrects)/corrects.shape[0])\n\nprint(\"CONFUSION MATRIX\")\nprint(sklearn.metrics.confusion_matrix(Ytestt,preds))\nprint()\nprint()\nprint(sklearn.metrics.classification_report(Ytestt,preds))\n\ncm = sklearn.metrics.confusion_matrix(Ytestt,preds)/np.sum(sklearn.metrics.confusion_matrix(Ytestt,preds),axis=0)\nhm=sns.heatmap(cm,annot=True,fmt=\".2f\")\nhm.set_xticklabels(['N','S','V'])\nhm.set_xlabel(\"Prediction\")\nhm.set_ylabel(\"Real\")\nhm.set_yticklabels(['N','S','V'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:35:14.021868Z","iopub.execute_input":"2022-01-08T11:35:14.022136Z","iopub.status.idle":"2022-01-08T11:38:15.167179Z","shell.execute_reply.started":"2022-01-08T11:35:14.022105Z","shell.execute_reply":"2022-01-08T11:38:15.166375Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"print(\">> TRAINING HISTORY\")\nplt.figure(figsize=(15,10))\nplt.subplot(3,1,1)\nplt.plot(history['loss'], label='Training Loss', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_loss'], label='Validation Loss', alpha=.9, color='#5a9aa5')\nplt.title('Loss')\nplt.legend()\nplt.grid(alpha=.3)\nplt.subplot(3,1,2)\nplt.plot(history['recall_S'], label='Training Recall S', alpha=.3, color='#ff0000')\nplt.plot(history['val_recall_S'], label='Validation Recall S', alpha=.9, color='#ff0000')\nplt.plot(history['recall_V'], label='Training Recall V', alpha=.3, color='#0000ff')\nplt.plot(history['val_recall_V'], label='Validation Recall V', alpha=.9, color='#0000ff')\nplt.title('Loss')\nplt.legend()\nplt.grid(alpha=.3)\nplt.subplot(3,1,3)\nplt.plot(history['accuracy'], label='Training Accuracy', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_accuracy'], label='Validation Accuracy', alpha=.9, color='#5a9aa5')\nplt.title('Accuracy')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:39:22.034829Z","iopub.execute_input":"2022-01-08T11:39:22.035091Z","iopub.status.idle":"2022-01-08T11:39:22.601903Z","shell.execute_reply.started":"2022-01-08T11:39:22.035061Z","shell.execute_reply":"2022-01-08T11:39:22.601162Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"# Testing and Esambling","metadata":{}},{"cell_type":"code","source":"preds= np.argmax( \n    timemodel.predict([XtestW, XtestP])+freqmodel.predict([fXtestW, fXtestP]),\n    axis=1\n)\n\nplt.figure(figsize=(10,5))\nplt.hist(timemodel.predict([XtestW, XtestP])[:,1],bins=10)\nplt.hist(timemodel.predict([XtestW, XtestP])[:,2],bins=10)\nplt.hist(timemodel.predict([XtestW, XtestP])[:,3],bins=10)\nplt.show()\nplt.figure(figsize=(20,10))\n\nplt.hist(freqmodel.predict([fXtestW, fXtestP])[:,1],bins=10)\nplt.hist(freqmodel.predict([fXtestW, fXtestP])[:,2],bins=10)\nplt.hist(freqmodel.predict([fXtestW, fXtestP])[:,3],bins=10)\n\nplt.show()\n\nYtestt = np.argmax(Ytest,axis=1)\ncorrects = preds==Ytestt\nprint(\"ACCURAY: \",np.count_nonzero(corrects)/corrects.shape[0])\n\nprint(\"CONFUSION MATRIX\")\nprint(sklearn.metrics.confusion_matrix(Ytestt,preds))\nprint()\nprint()\nprint(sklearn.metrics.classification_report(Ytestt,preds))\n\ncm = sklearn.metrics.confusion_matrix(Ytestt,preds)/np.sum(sklearn.metrics.confusion_matrix(Ytestt,preds),axis=0)\nhm=sns.heatmap(cm,annot=True,fmt=\".2f\")\nhm.set_xticklabels(['N','S','V'])\nhm.set_xlabel(\"Prediction\")\nhm.set_ylabel(\"Real\")\nhm.set_yticklabels(['N','S','V'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:39:49.790356Z","iopub.execute_input":"2022-01-08T11:39:49.790827Z","iopub.status.idle":"2022-01-08T11:39:53.770838Z","shell.execute_reply.started":"2022-01-08T11:39:49.790789Z","shell.execute_reply":"2022-01-08T11:39:53.769429Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"plt.plot(XtrainW[220,:,0])\n# plt.plot(np.abs(fXtrainW[100,:,1]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:28:53.033321Z","iopub.execute_input":"2022-01-08T11:28:53.033876Z","iopub.status.idle":"2022-01-08T11:28:53.224206Z","shell.execute_reply.started":"2022-01-08T11:28:53.033836Z","shell.execute_reply":"2022-01-08T11:28:53.223259Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"fXtrainW = np.fft.fft(XtrainW,axis=1)\n\nplt.plot(np.fft.fftshift(np.abs(fXtrainW[220,:,0])))\n# plt.plot(np.abs(fXtrainW[100,:,1]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:31:02.234072Z","iopub.execute_input":"2022-01-08T11:31:02.234985Z","iopub.status.idle":"2022-01-08T11:31:02.520123Z","shell.execute_reply.started":"2022-01-08T11:31:02.234933Z","shell.execute_reply":"2022-01-08T11:31:02.519280Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"timemodel.save(\"time.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-08T11:32:55.846363Z","iopub.execute_input":"2022-01-08T11:32:55.846795Z","iopub.status.idle":"2022-01-08T11:32:55.897307Z","shell.execute_reply.started":"2022-01-08T11:32:55.846755Z","shell.execute_reply":"2022-01-08T11:32:55.896529Z"},"trusted":true},"execution_count":113,"outputs":[]}]}